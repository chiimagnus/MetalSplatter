## Core ML 本地推理（零成本，纯 Swift 原生）

> **最优解。** 不需要服务器、不需要 Python、不需要 GPU 云。全程本地，完美契合「本地优先」。
> 

**成本**：$0

**核心能力**：社区已将 SHARP 转为 Core ML 格式，支持 CPU / GPU / Neural Engine 推理。

- M4 Max 推理 ~1.9 秒
- 输出标准 3DGS 参数（位置、缩放、旋转、颜色、透明度）
- 精度与 PyTorch 原版误差 < 0.01%
- 支持 **macOS / iOS / visionOS**

**模型来源**：[pearsonkyle/Sharp-coreml（HuggingFace）](https://huggingface.co/pearsonkyle/Sharp-coreml)

### 集成路线

**整体链路**：用户拍照 → Core ML 推理（~2s）→ 3DGS 参数 → MetalSplatter 渲染 → 展示

**Step 1：下载模型**

国内网络使用 HF Mirror 镜像（无需梯子）：

```bash
# 设置国内镜像源
export HF_ENDPOINT=https://hf-mirror.com

pip install huggingface-hub
huggingface-cli download --include sharp.mlpackage/ --local-dir . pearsonkyle/Sharp-coreml
```

或者克隆完整仓库（含推理脚本和转换代码）：

```bash
brew install git-xet
git xet install
git clone https://hf-mirror.com/pearsonkyle/Sharp-coreml
```

> 如果可以访问 HF 原站，把 `HF_ENDPOINT` 换成 [`https://huggingface.co`](https://huggingface.co) 或不设置即可。}
> 

将 `sharp.mlpackage` 放入 Xcode 项目。

**Step 2：推理层（参考 sharp.swift）**

模型输入：

- `image`：RGB 图片，`uint8`，shape `(1, 3, H, W)`，推荐 1536x1536
- `disparity_factor`：标量，`focal_length / image_width`，一般用 `1.0`

模型输出（5 个张量）：

| 输出 | Shape | 说明 |
| --- | --- | --- |
| `mean_vectors_3d_positions` | `(1, N, 3)` | 3D 位置（NDC 坐标） |
| `singular_values_scales` | `(1, N, 3)` | 各轴缩放参数 |
| `quaternions_rotations` | `(1, N, 4)` | 旋转四元数 `[w,x,y,z]` |
| `colors_rgb_linear` | `(1, N, 3)` | 线性 RGB 颜色 |
| `opacities_alpha_channel` | `(1, N)` | 透明度 |

N ≈ 1,179,648 个高斯点。

**Step 3：渲染层**

用 [MetalSplatter](https://github.com/scier/MetalSplatter) 渲染 3DGS：

- Swift Package，SPM 直接引入
- 兼容 SHARP 输出的 PLY 格式
- Metal 原生渲染，性能好

**Step 4：SwiftUI 展示**

MetalSplatter 提供 Metal view，用 `UIViewRepresentable`（iOS）或 `NSViewRepresentable`（macOS）包一层即可。visionOS 下可直接放进 ImmersiveSpace。